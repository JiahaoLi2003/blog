---
layout:     post
title:      MEMWALKER		# 标题 
subtitle: Walking Down the Memory Maze:Beyond Context Limit through Interactive Reading #副标题
date:       2023-10-28 				# 时间
author:     JiahaoLi 						# 作者
header-img: img/bolg-background.jpg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - LLMs
    - Memory  
    - Memory Tree
---

## 📖 Abstract

- Large language models (LLMs) have advanced in large strides due to the effectiveness of the self-attention mechanism that processes and compares all tokens at once.
- However, this mechanism comes with a fundamental issue — the predetermined context window is bound to be limited.
- 尽管尝试通过外推位置嵌入、使用递归或选择性检索长序列的重要部分等方法来扩展上下文窗口，但长文本理解仍然是一个挑战。
- 文章引入了MEMWALKER，这是一种首先将长上下文处理成摘要节点树的方法。在接收到查询后，模型导航该树以搜索相关信息，并在收集到足够信息后做出响应。
- On long-text question answering tasks, MEMWALKER outperforms baseline approaches that use long context windows, recurrence, and retrieval.

## 🧐 Methods

- 先讨论一下循环架构，循环架构已被广泛研究以解决长序列问题，从基于循环神经网络的模型到基于现代变压器的模型。然而，每个重复步骤都会导致信息丢失，并且训练目标不会指导关于下游任务的“如何压缩”。通常，这种压缩意味着与最近的信息相比，对旧序列信息的召回较弱
![](https://cdn.jsdelivr.net/gh/JiahaoLi2003/ImgHosting@main/Img/MEMWALKER.png)

MEMWALKER的两阶段过程：
- 阶段1 ———— 构建内存树
    - 将长文本拆分为预定大小的段，每个段首先汇总成一个摘要节点。摘要节点递归地汇总成更高级别的节点，直到到达根。
    - summ9=LLM（summ7，summ8）
    - summ7=LLM（summ1，summ2，summ3，summ4）
- 阶段2 ———— 查询内存树
    - 为了回答用户查询，LLM从树的根节点开始导航。它遍历树，检查文本的各个部分以识别与回答查询相关的路径和段。并且如果LLM选择了错误的路径或手头的段不相关（虚线红色箭头），则LLM可以选择恢复动作返回父节点。
示例如下：
![](https://cdn.jsdelivr.net/gh/JiahaoLi2003/ImgHosting@main/Img/MEMWALKER_example.png)
- LLM首先在根节点（summ 9）看到子节点的内容并生成响应（采取action 0输入summ 7）。当到达叶节点（summ 2）时，LLM确定没有足够的信息，因此采取行动恢复（action-1）到父节点。在节点之间来回跳跃后，LLM提交到叶节点（summ 3）并回答问题。黄色表示分类提示，紫色描述叶子提示。

## 🧪Experiment
- setting：use three datasets: QuALITY, SummScreenFD, and GovReport from the SCROLLS benchmark
    - 所有三个数据集都具有不同长度的每个示例的长上下文 - 一些较短的示例和一些较长的序列。
    - 既报告原始数据集的结果，又报告仅包含较长序列的每个任务的子集，以便更好地评估更困难、更长的上下文情况下的内存访问。
    - The thresholds are above 8, 000 tokens for QuALITY, 6, 000 tokens for SummScreenFD, and 12, 000 tokens for GovReport.
- result：
![](https://cdn.jsdelivr.net/gh/JiahaoLi2003/ImgHosting@main/Img/MEMWALKER_exp.png)
- Orig.表示使用整个数据集，Long表示较长序列的子集。顶部：与开源的长上下文模型的比较。底部：基线和MEMWALKER性能，所有方法都使用底层的Stable Beluga 2 LLM，最大上下文长度为4,096令牌。MEMWALKER在较长序列上的性能优于所有其他方法。



### 😉今天的分享就到这里啦，下次见咯
